{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# feature extractoring and preprocessing data\n",
    "import librosa\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import os\n",
    "from PIL import Image\n",
    "import pathlib\n",
    "import csv\n",
    "\n",
    "# Preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "\n",
    "#Keras\n",
    "import keras\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nDataset\\nWe use GTZAN genre collection dataset for classification. \\n\\nThe dataset consists of 10 genres i.e\\n\\nBlues\\nClassical\\nCountry\\nDisco\\nHiphop\\nJazz\\nMetal\\nPop\\nReggae\\nRock\\nEach genre contains 100 songs. Total dataset: 1000 songs\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extracting music and features\n",
    "'''\n",
    "Dataset\n",
    "We use GTZAN genre collection dataset for classification. \n",
    "\n",
    "The dataset consists of 10 genres i.e\n",
    "\n",
    "Blues\n",
    "Classical\n",
    "Country\n",
    "Disco\n",
    "Hiphop\n",
    "Jazz\n",
    "Metal\n",
    "Pop\n",
    "Reggae\n",
    "Rock\n",
    "Each genre contains 100 songs. Total dataset: 1000 songs\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Extracting the Spectrogram for every Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ncmap = plt.get_cmap(\\'inferno\\')\\n\\nplt.figure(figsize=(10,10))\\ngenres = \\'blues classical country disco hiphop jazz metal pop reggae rock\\'.split()\\nfor g in genres:\\n    pathlib.Path(f\\'img_data/{g}\\').mkdir(parents=True, exist_ok=True)     \\n    for filename in os.listdir(f\\'./MIR/genres/{g}\\'):\\n        songname = f\\'./MIR/genres/{g}/{filename}\\'\\n        y, sr = librosa.load(songname, mono=True, duration=5)\\n        plt.specgram(y, NFFT=2048, Fs=2, Fc=0, noverlap=128, cmap=cmap, sides=\\'default\\', mode=\\'default\\', scale=\\'dB\\');\\n        plt.axis(\\'off\\');\\n        plt.savefig(f\\'img_data/{g}/{filename[:-3].replace(\".\", \"\")}.png\\')\\n        plt.clf()\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "cmap = plt.get_cmap('inferno')\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "genres = 'blues classical country disco hiphop jazz metal pop reggae rock'.split()\n",
    "for g in genres:\n",
    "    pathlib.Path(f'img_data/{g}').mkdir(parents=True, exist_ok=True)     \n",
    "    for filename in os.listdir(f'./MIR/genres/{g}'):\n",
    "        songname = f'./MIR/genres/{g}/{filename}'\n",
    "        y, sr = librosa.load(songname, mono=True, duration=5)\n",
    "        plt.specgram(y, NFFT=2048, Fs=2, Fc=0, noverlap=128, cmap=cmap, sides='default', mode='default', scale='dB');\n",
    "        plt.axis('off');\n",
    "        plt.savefig(f'img_data/{g}/{filename[:-3].replace(\".\", \"\")}.png')\n",
    "        plt.clf()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nExtracting features from Spectrogram\\nWe will extract\\n\\nMel-frequency cepstral coefficients (MFCC)(20 in number)\\nSpectral Centroid,\\nZero Crossing Rate\\nChroma Frequencies\\nSpectral Roll-off.\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Extracting features from Spectrogram\n",
    "We will extract\n",
    "\n",
    "Mel-frequency cepstral coefficients (MFCC)(20 in number)\n",
    "Spectral Centroid,\n",
    "Zero Crossing Rate\n",
    "Chroma Frequencies\n",
    "Spectral Roll-off.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "header = 'filename chroma_stft rmse spectral_centroid spectral_bandwidth rolloff zero_crossing_rate'\n",
    "for i in range(1, 21):\n",
    "    header += f' mfcc{i}'\n",
    "header += ' label'\n",
    "header = header.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Writing data to csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfile = open('data.csv', 'w', newline='')\\nwith file:\\n    writer = csv.writer(file)\\n    writer.writerow(header)\\ngenres = 'blues classical country disco hiphop jazz metal pop reggae rock'.split()\\nfor g in genres:\\n    for filename in os.listdir(f'./MIR/genres/{g}'):\\n        songname = f'./MIR/genres/{g}/{filename}'\\n        y, sr = librosa.load(songname, mono=True, duration=30)\\n        chroma_stft = librosa.feature.chroma_stft(y=y, sr=sr)\\n        rmse = librosa.feature.rmse(y=y)\\n        spec_cent = librosa.feature.spectral_centroid(y=y, sr=sr)\\n        spec_bw = librosa.feature.spectral_bandwidth(y=y, sr=sr)\\n        rolloff = librosa.feature.spectral_rolloff(y=y, sr=sr)\\n        zcr = librosa.feature.zero_crossing_rate(y)\\n        mfcc = librosa.feature.mfcc(y=y, sr=sr)\\n        to_append = f'{filename} {np.mean(chroma_stft)} {np.mean(rmse)} {np.mean(spec_cent)} {np.mean(spec_bw)} {np.mean(rolloff)} {np.mean(zcr)}'    \\n        for e in mfcc:\\n            to_append += f' {np.mean(e)}'\\n        to_append += f' {g}'\\n        file = open('data.csv', 'a', newline='')\\n        with file:\\n            writer = csv.writer(file)\\n            writer.writerow(to_append.split())\\n\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "file = open('data.csv', 'w', newline='')\n",
    "with file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(header)\n",
    "genres = 'blues classical country disco hiphop jazz metal pop reggae rock'.split()\n",
    "for g in genres:\n",
    "    for filename in os.listdir(f'./MIR/genres/{g}'):\n",
    "        songname = f'./MIR/genres/{g}/{filename}'\n",
    "        y, sr = librosa.load(songname, mono=True, duration=30)\n",
    "        chroma_stft = librosa.feature.chroma_stft(y=y, sr=sr)\n",
    "        rmse = librosa.feature.rmse(y=y)\n",
    "        spec_cent = librosa.feature.spectral_centroid(y=y, sr=sr)\n",
    "        spec_bw = librosa.feature.spectral_bandwidth(y=y, sr=sr)\n",
    "        rolloff = librosa.feature.spectral_rolloff(y=y, sr=sr)\n",
    "        zcr = librosa.feature.zero_crossing_rate(y)\n",
    "        mfcc = librosa.feature.mfcc(y=y, sr=sr)\n",
    "        to_append = f'{filename} {np.mean(chroma_stft)} {np.mean(rmse)} {np.mean(spec_cent)} {np.mean(spec_bw)} {np.mean(rolloff)} {np.mean(zcr)}'    \n",
    "        for e in mfcc:\n",
    "            to_append += f' {np.mean(e)}'\n",
    "        to_append += f' {g}'\n",
    "        file = open('data.csv', 'a', newline='')\n",
    "        with file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow(to_append.split())\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Analysing the Data in Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>chroma_stft</th>\n",
       "      <th>rmse</th>\n",
       "      <th>spectral_centroid</th>\n",
       "      <th>spectral_bandwidth</th>\n",
       "      <th>rolloff</th>\n",
       "      <th>zero_crossing_rate</th>\n",
       "      <th>mfcc1</th>\n",
       "      <th>mfcc2</th>\n",
       "      <th>mfcc3</th>\n",
       "      <th>...</th>\n",
       "      <th>mfcc12</th>\n",
       "      <th>mfcc13</th>\n",
       "      <th>mfcc14</th>\n",
       "      <th>mfcc15</th>\n",
       "      <th>mfcc16</th>\n",
       "      <th>mfcc17</th>\n",
       "      <th>mfcc18</th>\n",
       "      <th>mfcc19</th>\n",
       "      <th>mfcc20</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>blues.00060.au</td>\n",
       "      <td>0.430894</td>\n",
       "      <td>0.196222</td>\n",
       "      <td>1946.565652</td>\n",
       "      <td>1979.909934</td>\n",
       "      <td>3955.867746</td>\n",
       "      <td>0.097454</td>\n",
       "      <td>-67.770980</td>\n",
       "      <td>111.704184</td>\n",
       "      <td>-34.646105</td>\n",
       "      <td>...</td>\n",
       "      <td>12.295832</td>\n",
       "      <td>-12.477988</td>\n",
       "      <td>1.681278</td>\n",
       "      <td>-5.142068</td>\n",
       "      <td>4.644002</td>\n",
       "      <td>-6.919217</td>\n",
       "      <td>1.040718</td>\n",
       "      <td>-4.736871</td>\n",
       "      <td>-0.660037</td>\n",
       "      <td>blues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>blues.00082.au</td>\n",
       "      <td>0.338896</td>\n",
       "      <td>0.251350</td>\n",
       "      <td>2141.461656</td>\n",
       "      <td>2168.015560</td>\n",
       "      <td>4627.997015</td>\n",
       "      <td>0.105151</td>\n",
       "      <td>-29.362093</td>\n",
       "      <td>108.667950</td>\n",
       "      <td>-25.573165</td>\n",
       "      <td>...</td>\n",
       "      <td>5.456504</td>\n",
       "      <td>-7.687713</td>\n",
       "      <td>7.410600</td>\n",
       "      <td>-11.319177</td>\n",
       "      <td>7.229288</td>\n",
       "      <td>-9.466552</td>\n",
       "      <td>1.930059</td>\n",
       "      <td>-6.328476</td>\n",
       "      <td>-1.304812</td>\n",
       "      <td>blues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>blues.00030.au</td>\n",
       "      <td>0.263016</td>\n",
       "      <td>0.170081</td>\n",
       "      <td>1379.081742</td>\n",
       "      <td>2004.000850</td>\n",
       "      <td>3015.831764</td>\n",
       "      <td>0.039376</td>\n",
       "      <td>-206.987590</td>\n",
       "      <td>117.781468</td>\n",
       "      <td>23.256245</td>\n",
       "      <td>...</td>\n",
       "      <td>-8.015467</td>\n",
       "      <td>-17.616342</td>\n",
       "      <td>-8.138554</td>\n",
       "      <td>-8.646157</td>\n",
       "      <td>-15.538988</td>\n",
       "      <td>-15.331506</td>\n",
       "      <td>-9.664872</td>\n",
       "      <td>-10.103310</td>\n",
       "      <td>-17.835100</td>\n",
       "      <td>blues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>blues.00007.au</td>\n",
       "      <td>0.307921</td>\n",
       "      <td>0.131785</td>\n",
       "      <td>1451.754147</td>\n",
       "      <td>1577.369917</td>\n",
       "      <td>2955.348796</td>\n",
       "      <td>0.061435</td>\n",
       "      <td>-179.395447</td>\n",
       "      <td>136.459244</td>\n",
       "      <td>-26.656359</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.954827</td>\n",
       "      <td>-3.544535</td>\n",
       "      <td>-8.051242</td>\n",
       "      <td>-8.959537</td>\n",
       "      <td>-8.424337</td>\n",
       "      <td>-10.558885</td>\n",
       "      <td>-10.788159</td>\n",
       "      <td>-4.693749</td>\n",
       "      <td>-8.638613</td>\n",
       "      <td>blues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>blues.00064.au</td>\n",
       "      <td>0.332480</td>\n",
       "      <td>0.117413</td>\n",
       "      <td>2553.232415</td>\n",
       "      <td>2280.128669</td>\n",
       "      <td>5148.102203</td>\n",
       "      <td>0.146852</td>\n",
       "      <td>-85.150250</td>\n",
       "      <td>88.806722</td>\n",
       "      <td>-16.322611</td>\n",
       "      <td>...</td>\n",
       "      <td>8.478453</td>\n",
       "      <td>-19.590226</td>\n",
       "      <td>6.413210</td>\n",
       "      <td>-13.779667</td>\n",
       "      <td>6.112037</td>\n",
       "      <td>-13.154644</td>\n",
       "      <td>3.933456</td>\n",
       "      <td>-7.615454</td>\n",
       "      <td>3.752626</td>\n",
       "      <td>blues</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         filename  chroma_stft      rmse  spectral_centroid  \\\n",
       "0  blues.00060.au     0.430894  0.196222        1946.565652   \n",
       "1  blues.00082.au     0.338896  0.251350        2141.461656   \n",
       "2  blues.00030.au     0.263016  0.170081        1379.081742   \n",
       "3  blues.00007.au     0.307921  0.131785        1451.754147   \n",
       "4  blues.00064.au     0.332480  0.117413        2553.232415   \n",
       "\n",
       "   spectral_bandwidth      rolloff  zero_crossing_rate       mfcc1  \\\n",
       "0         1979.909934  3955.867746            0.097454  -67.770980   \n",
       "1         2168.015560  4627.997015            0.105151  -29.362093   \n",
       "2         2004.000850  3015.831764            0.039376 -206.987590   \n",
       "3         1577.369917  2955.348796            0.061435 -179.395447   \n",
       "4         2280.128669  5148.102203            0.146852  -85.150250   \n",
       "\n",
       "        mfcc2      mfcc3  ...       mfcc12     mfcc13    mfcc14     mfcc15  \\\n",
       "0  111.704184 -34.646105  ...    12.295832 -12.477988  1.681278  -5.142068   \n",
       "1  108.667950 -25.573165  ...     5.456504  -7.687713  7.410600 -11.319177   \n",
       "2  117.781468  23.256245  ...    -8.015467 -17.616342 -8.138554  -8.646157   \n",
       "3  136.459244 -26.656359  ...    -6.954827  -3.544535 -8.051242  -8.959537   \n",
       "4   88.806722 -16.322611  ...     8.478453 -19.590226  6.413210 -13.779667   \n",
       "\n",
       "      mfcc16     mfcc17     mfcc18     mfcc19     mfcc20  label  \n",
       "0   4.644002  -6.919217   1.040718  -4.736871  -0.660037  blues  \n",
       "1   7.229288  -9.466552   1.930059  -6.328476  -1.304812  blues  \n",
       "2 -15.538988 -15.331506  -9.664872 -10.103310 -17.835100  blues  \n",
       "3  -8.424337 -10.558885 -10.788159  -4.693749  -8.638613  blues  \n",
       "4   6.112037 -13.154644   3.933456  -7.615454   3.752626  blues  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('data.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 28)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Dropping unneccesary columns\n",
    "data = data.drop(['filename'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Encoding the Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "genre_list = data.iloc[:, -1]\n",
    "encoder = LabelEncoder()\n",
    "y = encoder.fit_transform(genre_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Scaling the Feature columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(np.array(data.iloc[:, :-1], dtype = float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Dividing data into training and Testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "800"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.71595489, -0.63589658,  1.05952008,  0.59990028,  0.7811424 ,\n",
       "        0.41284744, -0.76332485, -1.86542645, -0.23416499, -0.16058369,\n",
       "        1.09112317, -0.08197994,  1.11531191, -0.23787937,  1.48397167,\n",
       "        0.34567857,  1.58239438,  0.30198017,  1.83009669,  0.73451768,\n",
       "        1.32239052, -0.60830427,  0.53152504,  0.66674309,  1.93340958,\n",
       "        1.25442381])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Classification with Keras\n",
    "# Building our Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(256, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "\n",
    "model.add(layers.Dense(128, activation='relu'))\n",
    "\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "\n",
    "model.add(layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "800/800 [==============================] - 2s 2ms/step - loss: 2.1790 - acc: 0.2112\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 83us/step - loss: 1.8650 - acc: 0.3887\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 100us/step - loss: 1.6385 - acc: 0.4262\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 91us/step - loss: 1.4634 - acc: 0.5125\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 100us/step - loss: 1.3121 - acc: 0.5550\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 77us/step - loss: 1.1986 - acc: 0.6275\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 81us/step - loss: 1.1067 - acc: 0.6438\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 79us/step - loss: 1.0210 - acc: 0.6687\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 110us/step - loss: 0.9571 - acc: 0.6875\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 85us/step - loss: 0.8972 - acc: 0.7075\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 77us/step - loss: 0.8514 - acc: 0.7137\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 81us/step - loss: 0.8110 - acc: 0.7375\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 103us/step - loss: 0.7665 - acc: 0.7462\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 74us/step - loss: 0.7229 - acc: 0.7650\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 85us/step - loss: 0.6845 - acc: 0.7900\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 96us/step - loss: 0.6592 - acc: 0.7950\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 94us/step - loss: 0.6405 - acc: 0.7850\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 73us/step - loss: 0.6089 - acc: 0.8050\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 78us/step - loss: 0.5795 - acc: 0.8212\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 147us/step - loss: 0.5499 - acc: 0.8337 0s - loss: 0.5528 - acc: 0.828\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train,\n",
    "                    y_train,\n",
    "                    epochs=20,\n",
    "                    batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - 0s 745us/step\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_acc:  0.7\n"
     ]
    }
   ],
   "source": [
    "print('test_acc: ',test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Tes accuracy is less than training data accuracy. This hints at Overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Validating our approach\n",
    "# Let's set apart 200 samples in our training data to use as a validation set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_val = X_train[:200]\n",
    "partial_x_train = X_train[200:]\n",
    "\n",
    "y_val = y_train[:200]\n",
    "partial_y_train = y_train[200:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Now let's train our network for 20 epochs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 600 samples, validate on 200 samples\n",
      "Epoch 1/30\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 2.3223 - acc: 0.0733 - val_loss: 2.1589 - val_acc: 0.2950\n",
      "Epoch 2/30\n",
      "600/600 [==============================] - 0s 119us/step - loss: 2.1226 - acc: 0.3517 - val_loss: 2.0320 - val_acc: 0.3300\n",
      "Epoch 3/30\n",
      "600/600 [==============================] - 0s 112us/step - loss: 1.9711 - acc: 0.3633 - val_loss: 1.9225 - val_acc: 0.3150\n",
      "Epoch 4/30\n",
      "600/600 [==============================] - 0s 110us/step - loss: 1.8310 - acc: 0.3733 - val_loss: 1.8215 - val_acc: 0.3400\n",
      "Epoch 5/30\n",
      "600/600 [==============================] - 0s 115us/step - loss: 1.7097 - acc: 0.3967 - val_loss: 1.7299 - val_acc: 0.4050\n",
      "Epoch 6/30\n",
      "600/600 [==============================] - 0s 108us/step - loss: 1.5954 - acc: 0.4600 - val_loss: 1.6492 - val_acc: 0.4400\n",
      "Epoch 7/30\n",
      "600/600 [==============================] - 0s 118us/step - loss: 1.4869 - acc: 0.5050 - val_loss: 1.5757 - val_acc: 0.4400\n",
      "Epoch 8/30\n",
      "600/600 [==============================] - 0s 113us/step - loss: 1.3933 - acc: 0.5417 - val_loss: 1.5107 - val_acc: 0.4700\n",
      "Epoch 9/30\n",
      "600/600 [==============================] - 0s 138us/step - loss: 1.2979 - acc: 0.5650 - val_loss: 1.4623 - val_acc: 0.4850\n",
      "Epoch 10/30\n",
      "600/600 [==============================] - 0s 89us/step - loss: 1.2105 - acc: 0.5567 - val_loss: 1.4557 - val_acc: 0.4850\n",
      "Epoch 11/30\n",
      "600/600 [==============================] - 0s 122us/step - loss: 1.1581 - acc: 0.5950 - val_loss: 1.4307 - val_acc: 0.5150\n",
      "Epoch 12/30\n",
      "600/600 [==============================] - 0s 125us/step - loss: 1.0869 - acc: 0.6200 - val_loss: 1.3934 - val_acc: 0.5400\n",
      "Epoch 13/30\n",
      "600/600 [==============================] - 0s 116us/step - loss: 1.0332 - acc: 0.6367 - val_loss: 1.3506 - val_acc: 0.5200\n",
      "Epoch 14/30\n",
      "600/600 [==============================] - 0s 115us/step - loss: 0.9806 - acc: 0.6767 - val_loss: 1.3555 - val_acc: 0.5000\n",
      "Epoch 15/30\n",
      "600/600 [==============================] - 0s 121us/step - loss: 0.9575 - acc: 0.6783 - val_loss: 1.3245 - val_acc: 0.5600\n",
      "Epoch 16/30\n",
      "600/600 [==============================] - 0s 99us/step - loss: 0.9004 - acc: 0.7083 - val_loss: 1.3249 - val_acc: 0.5200\n",
      "Epoch 17/30\n",
      "600/600 [==============================] - 0s 114us/step - loss: 0.8766 - acc: 0.7050 - val_loss: 1.2902 - val_acc: 0.5400\n",
      "Epoch 18/30\n",
      "600/600 [==============================] - 0s 102us/step - loss: 0.8241 - acc: 0.7483 - val_loss: 1.2926 - val_acc: 0.5400\n",
      "Epoch 19/30\n",
      "600/600 [==============================] - 0s 143us/step - loss: 0.7879 - acc: 0.7433 - val_loss: 1.2779 - val_acc: 0.5800\n",
      "Epoch 20/30\n",
      "600/600 [==============================] - 0s 125us/step - loss: 0.7384 - acc: 0.7650 - val_loss: 1.3198 - val_acc: 0.5700\n",
      "Epoch 21/30\n",
      "600/600 [==============================] - 0s 150us/step - loss: 0.7340 - acc: 0.7683 - val_loss: 1.3151 - val_acc: 0.5750\n",
      "Epoch 22/30\n",
      "600/600 [==============================] - 0s 152us/step - loss: 0.7073 - acc: 0.7733 - val_loss: 1.2833 - val_acc: 0.5550\n",
      "Epoch 23/30\n",
      "600/600 [==============================] - 0s 141us/step - loss: 0.6573 - acc: 0.7883 - val_loss: 1.2815 - val_acc: 0.5650\n",
      "Epoch 24/30\n",
      "600/600 [==============================] - 0s 177us/step - loss: 0.6276 - acc: 0.8083 - val_loss: 1.2940 - val_acc: 0.5750\n",
      "Epoch 25/30\n",
      "600/600 [==============================] - 0s 156us/step - loss: 0.6056 - acc: 0.8233 - val_loss: 1.2649 - val_acc: 0.5850\n",
      "Epoch 26/30\n",
      "600/600 [==============================] - 0s 156us/step - loss: 0.5794 - acc: 0.8350 - val_loss: 1.2378 - val_acc: 0.5900\n",
      "Epoch 27/30\n",
      "600/600 [==============================] - 0s 149us/step - loss: 0.5578 - acc: 0.8300 - val_loss: 1.2534 - val_acc: 0.6000\n",
      "Epoch 28/30\n",
      "600/600 [==============================] - 0s 132us/step - loss: 0.5329 - acc: 0.8350 - val_loss: 1.2866 - val_acc: 0.6100\n",
      "Epoch 29/30\n",
      "600/600 [==============================] - 0s 147us/step - loss: 0.5105 - acc: 0.8533 - val_loss: 1.3152 - val_acc: 0.5900\n",
      "Epoch 30/30\n",
      "600/600 [==============================] - 0s 152us/step - loss: 0.4947 - acc: 0.8583 - val_loss: 1.2882 - val_acc: 0.6000\n",
      "200/200 [==============================] - 0s 230us/step\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Dense(512, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "model.add(layers.Dense(256, activation='relu'))\n",
    "model.add(layers.Dense(128, activation='relu'))\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(partial_x_train,\n",
    "          partial_y_train,\n",
    "          epochs=30,\n",
    "          batch_size=512,\n",
    "          validation_data=(x_val, y_val))\n",
    "results = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0170895957946777, 0.70999999999999996]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Predictions on Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10,)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(predictions[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(predictions[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
